{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import cPickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items_set = set()\n",
    "for i in range(2515):\n",
    "    items_set.add(i)\n",
    "user_item_map=pickle.load(open('../data/new_data/user_item_map.pkl','rb'))\n",
    "item_id_lookup = pickle.load(open('../data/new_data/item_id_lookup.pkl','rb'))\n",
    "item_data=pickle.load(open('../data/processed_data/all_items','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2515, 327)\n"
     ]
    }
   ],
   "source": [
    "item_data_map=dict() #appid, item\n",
    "tags_set=set()\n",
    "for item in item_data:\n",
    "    item_data_map[int(item['appid'])]=item\n",
    "    for tag in item['tags']:\n",
    "        tags_set.add(tag)\n",
    "        \n",
    "tags_map=dict()\n",
    "ind_tags_map = dict()\n",
    "for i,tag in enumerate(tags_set):\n",
    "    tags_map[tag] = i \n",
    "    ind_tags_map[i] = tag\n",
    "    \n",
    "    \n",
    "def get_feat(tags):\n",
    "    feat=np.zeros(len(tags_map))\n",
    "    for tag in tags:\n",
    "        feat[tags_map[tag]]=1\n",
    "    return feat\n",
    "\n",
    "def get_item_data_map_id(index):\n",
    "    id = item_id_lookup[index]\n",
    "    for i in range(0,len(item_data)-1):\n",
    "        if int(item_data[i]['appid']) == id:\n",
    "            return i\n",
    "            \n",
    "tag_array = np.array([get_feat(item_data[get_item_data_map_id(i)]['tags']) for i in items_set])\n",
    "print(tag_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bundle_map=pickle.load(open('../data/new_data/user_bundle_map.pkl','rb')) \n",
    "bundle_item_map=pickle.load(open('../data/new_data/bundle_item_map.pkl','rb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n",
      "1244\n"
     ]
    }
   ],
   "source": [
    "tempitem_set = set()\n",
    "for u in user_bundle_map:\n",
    "    for b in user_bundle_map[u]:\n",
    "        for i in bundle_item_map[b]:\n",
    "            tempitem_set.add(i)\n",
    "print len(tempitem_set)\n",
    "\n",
    "boughtitems = set()\n",
    "for u in user_item_map:\n",
    "    for i in user_item_map[u]:\n",
    "        boughtitems.add(i)\n",
    "print len(boughtitems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data=[] #list: [(user index, bundle index)]\n",
    "\n",
    "for user,bundles in user_bundle_map.items():\n",
    "    for bundle in bundles:\n",
    "        all_data.append((user,bundle))\n",
    "        \n",
    "all_item_data=[] #list: [(user index, item index)]\n",
    "for user,items in user_item_map.items():\n",
    "    for item in items:\n",
    "        all_item_data.append((user,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(all_data)\n",
    "random.shuffle(all_item_data)\n",
    "\n",
    "# Training data for bundle for bpr model\n",
    "training_data=all_data[:int(0.8*len(all_data))]\n",
    "test_data=all_data[int(0.8*len(all_data)):]\n",
    "\n",
    "# Training data for items for bpr_item model\n",
    "training_data_2=all_item_data[:int(0.8*len(all_item_data))]\n",
    "test_data_2=all_item_data[int(0.8*len(all_item_data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if user1's item/bundle is not in user2's bundle map, and user2's item/bundle is not in user1's\n",
    "def check_tuple(tuple_1, tuple_2, user_bundle_map):\n",
    "    return tuple_1[1] not in user_bundle_map[tuple_2[0]] and tuple_2[1] not in user_bundle_map[tuple_1[0]]\n",
    "\n",
    "#negative items and bundles follow the same degree distribution\n",
    "def graph_sampling(n_samples, training_data, user_bundle_map):\n",
    "    sgd_users=[]\n",
    "    sgd_pos_items, sgd_neg_items = [], []\n",
    "    i=0\n",
    "    while n_samples>0:\n",
    "        if i%100000==0:\n",
    "            print i\n",
    "        i+=1\n",
    "        tuple_1=training_data[np.random.randint(len(training_data))]\n",
    "        tuple_2=training_data[np.random.randint(len(training_data))]\n",
    "        iteration=100\n",
    "        while not check_tuple(tuple_1, tuple_2, user_bundle_map):\n",
    "            tuple_2=training_data[np.random.randint(len(training_data))]\n",
    "            iteration-=1\n",
    "            if iteration == 0:\n",
    "                break\n",
    "        if iteration==0:\n",
    "            continue   \n",
    "        sgd_neg_items.append(tuple_2[1])\n",
    "        sgd_pos_items.append(tuple_1[1])\n",
    "        sgd_users.append(tuple_1[0])\n",
    "        \n",
    "        sgd_neg_items.append(tuple_1[1])\n",
    "        sgd_pos_items.append(tuple_2[1])\n",
    "        sgd_users.append(tuple_2[0])\n",
    "        n_samples-=2\n",
    "    return sgd_users, sgd_pos_items, sgd_neg_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n"
     ]
    }
   ],
   "source": [
    "# Generting training data for items through graph sampling.\n",
    "sgd_train_users_items, sgd_train_pos_items, sgd_train_neg_items = graph_sampling(len(training_data_2)*30, training_data_2, user_item_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "[206, 1487, 158, 1990, 206] 18615300\n",
      "[1487, 206, 1990, 158, 124] 18615300\n"
     ]
    }
   ],
   "source": [
    "print type(sgd_train_pos_items)\n",
    "print sgd_train_pos_items[0:5], len(sgd_train_pos_items)\n",
    "print sgd_train_neg_items[0:5], len(sgd_train_neg_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_data_items(test_data, train_data):\n",
    "    users=[]\n",
    "    pos_items=[]\n",
    "    neg_items=[]\n",
    "    train_dict, train_users, train_items  = data_to_dict(train_data)\n",
    "    test_dict, test_users, test_items = data_to_dict(test_data)\n",
    "    z = 0\n",
    "    for i,user in enumerate(test_dict.keys()):\n",
    "        if(i%1000==0):\n",
    "            print i\n",
    "\n",
    "        if user in train_users: \n",
    "            for pos_item in test_dict[user]:\n",
    "                if pos_item in train_items:\n",
    "                    for neg_item in train_items:\n",
    "                        if neg_item not in test_dict[user] and neg_item not in train_dict[user]:\n",
    "                            users.append(user)\n",
    "                            pos_items.append(pos_item)\n",
    "                            neg_items.append(neg_item)\n",
    "\n",
    "    return users, pos_items, neg_items\n",
    "\n",
    "\n",
    "def data_to_dict(data):\n",
    "    data_dict = defaultdict(list)\n",
    "    items = set()\n",
    "    for (user, item) in data:\n",
    "        data_dict[user].append(item)\n",
    "        items.add(item)\n",
    "    return data_dict, set(data_dict.keys()), items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n"
     ]
    }
   ],
   "source": [
    "test_users_cold, test_pos_items_cold, test_neg_items_cold = get_test_data_items(test_data_2, training_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new test data length: 4025471\n"
     ]
    }
   ],
   "source": [
    "new_test_users=[]\n",
    "new_test_pos=[]\n",
    "new_test_neg=[]\n",
    "\n",
    "for i in range(len(test_users_cold)):\n",
    "    if(i%45==0):\n",
    "        new_test_users.append(test_users_cold[i])\n",
    "        new_test_pos.append(test_pos_items_cold[i])\n",
    "        new_test_neg.append(test_neg_items_cold[i])\n",
    "print \"new test data length:\", len(new_test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_users_cold,test_pos_items_cold,test_neg_items_cold = new_test_users, new_test_pos, new_test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=cpu,lib.cnmem=0.7,floatX=float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# theano-bpr\n",
    "#\n",
    "# Copyright (c) 2014 British Broadcasting Corporation\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import theano, numpy\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "class BPR_Item(object):\n",
    "\n",
    "    def __init__(self, rank, n_users, n_items, n_tags, tag_array, lambda_u = 0.0025, lambda_i = 0.0025, lambda_j = 0.00025, lambda_d = 0.0025, lambda_p = 0.00025, lambda_q = 0.00025, lambda_bias = 0.0, learning_rate = 0.05):\n",
    "        \n",
    "        self._rank = rank\n",
    "        self._n_users = n_users\n",
    "        self._n_items = n_items\n",
    "        self._n_tags = n_tags\n",
    "        self._lambda_u = lambda_u\n",
    "        self._lambda_i = lambda_i\n",
    "        self._lambda_j = lambda_j\n",
    "        self._lambda_d = lambda_d\n",
    "        self._lambda_p = lambda_p\n",
    "        self._lambda_q = lambda_q\n",
    "        self._lambda_bias = lambda_bias\n",
    "        self._learning_rate = learning_rate\n",
    "        self.TG = theano.shared(tag_array.astype('float32'), name='TG')\n",
    "        self._configure_theano()\n",
    "        self._generate_train_model_function()\n",
    "        self._generate_test_model_function()\n",
    "\n",
    "    def _configure_theano(self):\n",
    "        \"\"\"\n",
    "          Configures Theano to run in fast mode\n",
    "          and using 32-bit floats. \n",
    "        \"\"\"\n",
    "        theano.config.mode = 'FAST_RUN'\n",
    "        theano.config.floatX = 'float32'\n",
    "\n",
    "    def _generate_train_model_function(self):\n",
    "        u = T.lvector('u')\n",
    "        i = T.lvector('i')\n",
    "        j = T.lvector('j')\n",
    "\n",
    "        h = numpy.random.random((self._n_items, self._rank))\n",
    "        b = numpy.random.random(self._n_items)#1*n_items\n",
    "        x = numpy.random.random((self._n_users, self._n_tags))\n",
    "#         tg = numpy.random.random((self._n_items, self._n_tags))\n",
    "        #### needs change ###\n",
    "        \n",
    "        self.W = theano.shared(numpy.random.random((self._n_users, self._rank)).astype('float32'), name='W')#P\n",
    "        self.H = theano.shared(h.astype('float32'), name='H')#Q\n",
    "        self.theta = theano.shared(x.astype('float32'), name='theta')\n",
    "        self.B = theano.shared(b.astype('float32'), name='B')#beta\n",
    "#         self.TG = theano.shared(tg.astype('float32'), name='TG')\n",
    "\n",
    "        \n",
    "#         A = theano.shared(tag_matrix.astype(\"int32\"))\n",
    "        #nd_list = numpy.asarray(item_data)\n",
    "        #theano_item_data = theano.shared(nd_list)\n",
    "        #self.A_i = theano.shared(get_feat(theano_item_data[i]['tags']),name='A_i')\n",
    "        #self.A_j = theano.shared(get_feat(theano_item_data[j]['tags']),name='A_j')\n",
    "        \n",
    "        #x_ui = B_i+P_u*Q_i+X_u*A_i\n",
    "        self.W[u]\n",
    "        x_ui = T.dot(self.W[u], self.H[i].T).diagonal() + self.B[i] + T.dot(self.theta[u], self.TG[i].T).diagonal()\n",
    "        x_uj = T.dot(self.W[u], self.H[j].T).diagonal() + self.B[j] + T.dot(self.theta[u], self.TG[j].T).diagonal()\n",
    "        x_uij = T.nnet.sigmoid(x_ui-x_uj)\n",
    "        \n",
    "        obj = T.sum(T.log(x_uij) - self._lambda_u * (self.W[u] ** 2).sum(axis=1) - \n",
    "                    self._lambda_i * (self.H[i] ** 2).sum(axis=1) - self._lambda_j * \n",
    "                    (self.H[j] ** 2).sum(axis=1) - self._lambda_bias * \n",
    "                    (self.B[i] ** 2 + self.B[j] ** 2) - self._lambda_d * (self.theta[u] ** 2).sum(axis=1))\n",
    "        \n",
    "        T.printing.Print('still training')\n",
    "    \n",
    "        cost = - obj\n",
    "\n",
    "        g_cost_W = T.grad(cost=cost, wrt=self.W)\n",
    "        g_cost_H = T.grad(cost=cost, wrt=self.H)\n",
    "        g_cost_B = T.grad(cost=cost, wrt=self.B)\n",
    "        g_cost_theta = T.grad(cost=cost, wrt=self.theta)\n",
    "\n",
    "        updates = [(self.W, self.W - self._learning_rate * g_cost_W), (self.H, self.H - self._learning_rate * g_cost_H), \n",
    "                   (self.B, self.B - self._learning_rate * g_cost_B), (self.theta, self.theta - self._learning_rate * g_cost_theta)]\n",
    "        \n",
    "                                                  #u, i_p, i_n    \n",
    "        self.train_model = theano.function(inputs=[u, i, j], outputs=cost, updates=updates)\n",
    "\n",
    "    \n",
    "    def train(self, s_users=None, s_pos_items=None, s_neg_items=None, batch_size=1000):\n",
    "        \"\"\"\n",
    "          Trains the BPR Matrix Factorisation model using Stochastic\n",
    "          Gradient Descent and minibatches over `train_data`.\n",
    "\n",
    "          `train_data` is an array of (user_index, item_index) tuples.\n",
    "\n",
    "          We first create a set of random samples from `train_data` for \n",
    "          training, of size `epochs` * size of `train_data`.\n",
    "\n",
    "          We then iterate through the resulting training samples by\n",
    "          batches of length `batch_size`, and run one iteration of gradient\n",
    "          descent for the batch.\n",
    "        \"\"\"\n",
    "        if len(s_pos_items) < batch_size:\n",
    "            sys.stderr.write(\"WARNING: Batch size is greater than number of training samples, switching to a batch size of %s\\n\" % str(len(train_data)))\n",
    "            batch_size = len(s_pos_items)\n",
    "            \n",
    "        sgd_users, sgd_pos_items, sgd_neg_items = s_users, s_pos_items, s_neg_items\n",
    "        n_sgd_samples = len(s_users)\n",
    "        \n",
    "        z = 0\n",
    "        t2 = t1 = t0 = time.time()\n",
    "        while (z+1)*batch_size < n_sgd_samples:\n",
    "            self.train_model(\n",
    "                sgd_users[z*batch_size: (z+1)*batch_size],\n",
    "                sgd_pos_items[z*batch_size: (z+1)*batch_size],\n",
    "                sgd_neg_items[z*batch_size: (z+1)*batch_size]\n",
    "            )\n",
    "            z += 1\n",
    "            t2 = time.time()\n",
    "            sys.stderr.write(\"\\rProcessed %s ( %.2f%% ) in %.4f seconds\" %(str(z*batch_size), 100.0 * float(z*batch_size)/n_sgd_samples, t2 - t1))\n",
    "            sys.stderr.flush()\n",
    "            t1 = t2\n",
    "        if n_sgd_samples > 0:\n",
    "            sys.stderr.write(\"\\nTotal training time %.2f seconds; %e per sample\\n\" % (t2 - t0, (t2 - t0)/n_sgd_samples))\n",
    "            sys.stderr.flush()\n",
    "            \n",
    "    def _generate_test_model_function(self):\n",
    "        \"\"\"\n",
    "          Computes item predictions for `user_index`.\n",
    "          Returns an array of prediction values for each item\n",
    "          in the dataset.\n",
    "        \"\"\"\n",
    "        u = T.lvector('u')\n",
    "        i = T.lvector('i')\n",
    "        j = T.lvector('j')\n",
    "        \n",
    "        x_ui = T.dot(self.W[u], self.H[i].T).diagonal() + self.B[i] + T.dot(self.theta[u], self.TG[i].T).diagonal()\n",
    "        x_uj = T.dot(self.W[u], self.H[j].T).diagonal() + self.B[j] + T.dot(self.theta[u], self.TG[j].T).diagonal()\n",
    "        x_uij = x_ui-x_uj\n",
    "        \n",
    "        self.test_model = theano.function(inputs=[u, i, j], outputs=x_uij)\n",
    "   \n",
    "    def test_bundle(self, sgd_users, sgd_pos_items, sgd_neg_items, batch_size=1000):\n",
    "        \"\"\"\n",
    "          Computes the Area Under Curve (AUC) on `test_data`.\n",
    "\n",
    "          `test_data` is an array of (user_index, item_index) tuples.\n",
    "\n",
    "          During this computation we ignore users and items\n",
    "          that didn't appear in the training data, to allow\n",
    "          for non-overlapping training and testing sets.\n",
    "        \"\"\"\n",
    "        \n",
    "        auc_values = []\n",
    "        z = 0\n",
    "        t2 = t1 = t0 = time.time()\n",
    "        n_sgd_samples = len(sgd_users)\n",
    "        while (z+1)*batch_size < n_sgd_samples:\n",
    "            pref_list=self.test_model(\n",
    "                sgd_users[z*batch_size: (z+1)*batch_size],\n",
    "                sgd_pos_items[z*batch_size: (z+1)*batch_size],\n",
    "                sgd_neg_items[z*batch_size: (z+1)*batch_size]\n",
    "            )\n",
    "            z += 1\n",
    "            t2 = time.time()\n",
    "            sys.stderr.write(\"\\rProcessed %s ( %.2f%% ) in %.4f seconds\" %(str(z*batch_size), 100.0 * float(z*batch_size)/n_sgd_samples, t2 - t1))\n",
    "            t1 = t2\n",
    "            \n",
    "            auc = np.sum([1.0 if a>0.0 else 0.0 for a in pref_list])\n",
    "            auc /= batch_size\n",
    "            \n",
    "            auc_values.append(auc)\n",
    "            sys.stderr.write(\"\\rCurrent AUC mean (%s samples): %0.5f\" % (str(z*batch_size), numpy.mean(auc_values)))\n",
    "            sys.stderr.flush()\n",
    "        \n",
    "        sys.stderr.write(\"\\n\")\n",
    "        sys.stderr.flush()\n",
    "        return numpy.mean(auc_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bpr_item = BPR_Item(10, len(user_item_map.keys()), len(items_set), len(tags_map), tag_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cPickle.dump(sgd_train_users_items, open('../train_test_data2/sgd_train_users_items.pkl', 'w'))\n",
    "# cPickle.dump(sgd_train_pos_items, open('../train_test_data2/sgd_train_pos_items.pkl', 'w'))\n",
    "# cPickle.dump(sgd_train_neg_items, open('../train_test_data2/sgd_train_neg_items.pkl', 'w'))\n",
    "# cPickle.dump(test_users_cold, open('../train_test_data2/test_users_cold.pkl', 'w'))\n",
    "# cPickle.dump(test_pos_items_cold, open('../train_test_data2/test_pos_items_cold.pkl', 'w'))\n",
    "# cPickle.dump(test_neg_items_cold, open('../train_test_data2/test_neg_items_cold.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-766ba1e59cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msgd_train_users_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sgd_train_users_items.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msgd_train_pos_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sgd_train_pos_items.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msgd_train_neg_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sgd_train_neg_items.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_users_cold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_users_cold.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "sgd_train_users_items = cPickle.load(open('sgd_train_users_items.pkl', 'r'))\n",
    "sgd_train_pos_items = cPickle.load(open('sgd_train_pos_items.pkl', 'r'))\n",
    "sgd_train_neg_items = cPickle.load(open('sgd_train_neg_items.pkl', 'r'))\n",
    "test_users_cold = cPickle.load(open('test_users_cold.pkl', 'r'))\n",
    "test_pos_items_cold = cPickle.load(open('test_pos_items_cold.pkl', 'r'))\n",
    "test_neg_items_cold = cPickle.load(open('test_neg_items_cold.pkl', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed 18615000 ( 100.00% ) in 0.0697 seconds\n",
      "Total training time 1739.04 seconds; 9.341977e-05 per sample\n"
     ]
    }
   ],
   "source": [
    "bpr_item.train(s_users=sgd_train_users_items, s_pos_items=sgd_train_pos_items, s_neg_items=sgd_train_neg_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current AUC mean (4025000 samples): 0.88859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88858757763975149"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_item.test_bundle(test_users_cold, test_pos_items_cold, test_neg_items_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cPickle.dump(bpr_item, open('../train_test_data2/bpr_item.pkl', 'w'))\n",
    "bpr_item = pickle.load(open('../train_test_data2/bpr_item.pkl', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n"
     ]
    }
   ],
   "source": [
    "# Generting training data for bundles through graph sampling.\n",
    "sgd_users, sgd_pos_bundles, sgd_neg_bundles = graph_sampling(len(training_data)*60, training_data, user_bundle_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4202280\n"
     ]
    }
   ],
   "source": [
    "print len(sgd_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_bundle_size 82\n",
      "2515\n"
     ]
    }
   ],
   "source": [
    "# Determining max bundle size to create bins for N\n",
    "max_bundle_size=0\n",
    "for bundle,items in bundle_item_map.items():\n",
    "    if(len(items)>max_bundle_size):\n",
    "        max_bundle_size=len(items)\n",
    "print 'max_bundle_size', max_bundle_size\n",
    "print len(items_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_items(bundle_id, max_bundle_size, index):\n",
    "    item=list(bundle_item_map[bundle_id]);\n",
    "    for i in range(len(item),max_bundle_size):\n",
    "        item.append(index)\n",
    "    return item\n",
    "\n",
    "sgd_pos_items=[get_items(b_id, max_bundle_size, len(items_set)) for b_id in sgd_pos_bundles]\n",
    "sgd_neg_items=[get_items(b_id, max_bundle_size, len(items_set)) for b_id in sgd_neg_bundles]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4202280\n"
     ]
    }
   ],
   "source": [
    "print len(sgd_pos_bundles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cPickle.dump(sgd_pos_bundles, open('../train_test_data2/sgd_pos_bundles.pkl', 'w'))\n",
    "# cPickle.dump(sgd_neg_bundles, open('../train_test_data2/sgd_neg_bundles.pkl', 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def compute_diversity_tags(app_data):\n",
    "    l=len(app_data)\n",
    "    app_data=[item_id_lookup[d] for d in app_data]\n",
    "    count=0.0\n",
    "    similarity=0.0\n",
    "    for i in range(l):\n",
    "        if app_data[i] in item_data_map:\n",
    "            for j in range(i+1,l):\n",
    "                if app_data[j] in item_data_map:\n",
    "                    count+=1\n",
    "                    similarity+=jaccard_similarity_score(get_feat(item_data_map[app_data[i]]['tags']),\n",
    "                                                         get_feat(item_data_map[app_data[j]]['tags']))\n",
    "    if count>0:\n",
    "        return 1-(similarity/count)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def compute_diversity_latent(app_data, H):\n",
    "    l=len(app_data)\n",
    "    count=0.0\n",
    "    similarity=0.0\n",
    "    for i in range(l):\n",
    "            for j in range(i+1,l):\n",
    "                    itemID1, itemID2 = app_data[i], app_data[j]\n",
    "                    count+=1\n",
    "#                     similarity+=cosine_similarity(H[itemID1].reshape(1,-1),H[itemID2].reshape(1,-1))[0,0]\n",
    "                    temp1, temp2 = pearsonr(H[itemID1].reshape(-1),H[itemID2].reshape(-1))\n",
    "                    similarity+=temp1\n",
    "    if count>0:\n",
    "        return 1-(similarity/count)\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def compute_diversity(app_data, H):\n",
    "    if H is not None:\n",
    "        return compute_diversity_latent(app_data, H)\n",
    "    else :\n",
    "        return compute_diversity_tags(app_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Gamma=bpr_item.H.eval()\n",
    "bundle_diversity_map=dict()\n",
    "for bundle,items in bundle_item_map.items():\n",
    "    bundle_diversity_map[bundle]=compute_diversity_latent(list(items), bpr_item.H.eval())\n",
    "\n",
    "#bundle_diversity_map=pickle.load(open('../../data/pickle/training_data/game_aus/bpr/bundle_diversity_map','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_pos_len=[len(bundle_item_map[b_id]) for b_id in sgd_pos_bundles]\n",
    "sgd_neg_len=[len(bundle_item_map[b_id]) for b_id in sgd_neg_bundles]\n",
    "sgd_pos_diversity=[bundle_diversity_map[b_id] for b_id in sgd_pos_bundles]\n",
    "sgd_neg_diversity=[bundle_diversity_map[b_id] for b_id in sgd_neg_bundles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_data_bundles(test_data, train_data, n_items):\n",
    "    users=[]\n",
    "    pos_bundles=[]\n",
    "    neg_bundles=[]\n",
    "    n1=[]\n",
    "    n2=[]\n",
    "    pos_diversity=[]\n",
    "    neg_diversity=[]\n",
    "    train_dict, train_users, train_items  = data_to_dict(train_data)\n",
    "    test_dict, test_users, test_items = data_to_dict(test_data)\n",
    "    auc_values = []\n",
    "    z = 0\n",
    "    for i,user in enumerate(test_dict.keys()):\n",
    "        if(i%1000==0):\n",
    "            print i\n",
    "\n",
    "        if user in train_users: \n",
    "            for pos_item in test_dict[user]:\n",
    "                if pos_item in train_items:\n",
    "                    for neg_item in train_items:\n",
    "                        if neg_item not in test_dict[user] and neg_item not in train_dict[user]:\n",
    "                            pos_diversity.append(bundle_diversity_map[pos_item])\n",
    "                            neg_diversity.append(bundle_diversity_map[neg_item])\n",
    "                            users.append(user)\n",
    "                            pos_bundles.append(pos_item)\n",
    "                            neg_bundles.append(neg_item)\n",
    "                            n1.append(len(bundle_item_map[pos_item]))\n",
    "                            n2.append(len(bundle_item_map[neg_item]))\n",
    "\n",
    "    pos_items=[get_items(b_id, max_bundle_size, n_items) for b_id in pos_bundles]\n",
    "    neg_items=[get_items(b_id, max_bundle_size, n_items) for b_id in neg_bundles]\n",
    "    \n",
    "    return users, pos_items, neg_items, n1, n2, pos_diversity, neg_diversity, pos_bundles, neg_bundles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "test_users, test_pos_items, test_neg_items, test_n1, test_n2, test_pos_diversity, test_neg_diversity,\\\n",
    "test_pos_bundles, test_neg_bundles= get_test_data_bundles(test_data, training_data, len(items_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_pos_bundles = cPickle.load(open('../train_test_data2/test_pos_bundles.pkl', 'r'))\n",
    "# test_neg_bundles = cPickle.load(open('../train_test_data2/test_neg_bundles.pkl', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pos_bundles=[bundle_diversity_map[b_id] for b_id in test_pos_bundles]\n",
    "test_neg_bundles=[bundle_diversity_map[b_id] for b_id in test_neg_bundles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3124050\n"
     ]
    }
   ],
   "source": [
    "print len(test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new test data length: 840456\n"
     ]
    }
   ],
   "source": [
    "permu = np.random.permutation(len(test_users))\n",
    "test_users = np.array(test_users)[permu][:len(sgd_users)/5]\n",
    "test_pos_items = np.array(test_pos_items)[permu][:len(sgd_users)/5]\n",
    "test_neg_items = np.array(test_neg_items)[permu][:len(sgd_users)/5]\n",
    "test_n1 = np.array(test_n1)[permu][:len(sgd_users)/5]\n",
    "test_n2 = np.array(test_n2)[permu][:len(sgd_users)/5]\n",
    "test_pos_diversity = np.array(test_pos_diversity)[permu][:len(sgd_users)/5]\n",
    "test_neg_diversity = np.array(test_neg_diversity)[permu][:len(sgd_users)/5]\n",
    "test_pos_bundles = np.array(test_pos_bundles)[permu][:len(sgd_users)/5]\n",
    "test_neg_bundles = np.array(test_neg_bundles)[permu][:len(sgd_users)/5]\n",
    "\n",
    "print \"new test data length:\", len(test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2515, 10)\n",
      "(2516, 10)\n",
      "(2515,)\n",
      "(2516,)\n",
      "(2515, 327)\n",
      "(2516, 327)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(bpr_item.H.eval())\n",
    "H_item=bpr_item.H.eval()\n",
    "H_item = np.concatenate((H_item,np.zeros((1,np.shape(H_item)[1]))),axis=0)\n",
    "H_item=np.array(H_item).astype('float32')\n",
    "print np.shape(H_item)\n",
    "\n",
    "print np.shape(bpr_item.B.eval())\n",
    "B_item=bpr_item.B.eval()\n",
    "B_item = np.append(B_item,0)\n",
    "B_item=np.array(B_item).astype('float32')\n",
    "print np.shape(B_item)\n",
    "\n",
    "print np.shape(bpr_item.TG.eval())\n",
    "TG_item = bpr_item.TG.eval()\n",
    "TG_item = np.concatenate((TG_item,np.zeros((1,np.shape(TG_item)[1]))),axis=0)\n",
    "TG_item=np.array(TG_item).astype('float32')\n",
    "print np.shape(TG_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano, numpy\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "class BPR_Cold(object):\n",
    "\n",
    "    def __init__(self, rank, bundle_size, n_users, n_items, n_tags, lambda_u = 0.0025, lambda_i = 0.0025, lambda_j = 0.00025, lambda_d = 0.0025, lambda_p = 0.00025, lambda_A = 0.003, lambda_bias = 0.0, learning_rate = 0.05):\n",
    "        \n",
    "        self._rank = rank\n",
    "        self._bundle_rank = bundle_size + 1\n",
    "        self._n_users = n_users\n",
    "        self._n_items = n_items\n",
    "        self._lambda_u = lambda_u\n",
    "        self._lambda_i = lambda_i\n",
    "        self._lambda_j = lambda_j\n",
    "        self._lambda_d = lambda_d\n",
    "        self._lambda_p = lambda_p\n",
    "        self._lambda_bias = lambda_bias\n",
    "        self._lambda_A = lambda_A\n",
    "        self._learning_rate = learning_rate\n",
    "        \n",
    "        self._n_tags = n_tags\n",
    "        self._configure_theano()\n",
    "        self._generate_train_model_item_function()\n",
    "        self._generate_test_model_function()\n",
    "\n",
    "    def _configure_theano(self):\n",
    "        theano.config.mode = 'FAST_RUN'\n",
    "        theano.config.floatX = 'float32'\n",
    "    \n",
    "    def _generate_train_model_item_function(self):\n",
    "        u = T.lvector('u')\n",
    "        i = T.lmatrix('i')\n",
    "        j = T.lmatrix('j')\n",
    "        n1 = T.lvector('n1')#num of items in pos bundle\n",
    "        n2 = T.lvector('n2')\n",
    "        di = T.dvector('di')#cb\n",
    "        dj = T.dvector('dj')#cb\n",
    "        \n",
    "        self.W1 = bpr_item.W #Pu\n",
    "        self.H1 = theano.shared(H_item.astype('float32'), name='H')#Qi\n",
    "        self.B1 = theano.shared(B_item.astype('float32'), name='B')#Bi\n",
    "        self.TG1 = theano.shared(TG_item.astype('float32'), name='TG')\n",
    "        self.theta1 = bpr_item.theta\n",
    "        \n",
    "        self.M1 = theano.shared(numpy.random.random((self._rank, self._rank)).astype('float64'), name='M1')#w\n",
    "        self.M2 = theano.shared(numpy.random.random((self._rank, self._rank)).astype('float64'), name='M2')#u\n",
    "        self.K = theano.shared(numpy.random.rand(), name='K')#k\n",
    "        self.D = theano.shared(numpy.random.random(self._n_users), name='D')#C\n",
    "        self.N = theano.shared(numpy.random.random(self._bundle_rank).astype('float32'), name='N')#Nb\n",
    "        self.A1 = theano.shared(numpy.random.random((self._n_tags, self._n_tags)), name='A1')\n",
    "        self.A2 = theano.shared(numpy.random.random((self._n_tags, self._n_tags)), name='A2')\n",
    "                                \n",
    "        \n",
    "        x_ui = T.dot(T.dot(self.W1[u],self.M2), T.dot(self.M1, self.H1[i].sum(axis=1).T/n1)).diagonal() + self.K*(self.B1[i].T/n1).T.sum(axis=1) + self.N[n1] + self.D[u]*di + T.dot(T.dot(self.theta1[u],self.A1), T.dot(self.A2, self.TG1[i].sum(axis=1).T/n1)).diagonal()\n",
    "        x_uj = T.dot(T.dot(self.W1[u],self.M2), T.dot(self.M1, self.H1[j].sum(axis=1).T/n2)).diagonal() + self.K*(self.B1[j].T/n2).T.sum(axis=1) + self.N[n2] + self.D[u]*dj + T.dot(T.dot(self.theta1[u],self.A1), T.dot(self.A2, self.TG1[j].sum(axis=1).T/n2)).diagonal()\n",
    "        \n",
    "        x_uij = T.nnet.sigmoid(x_ui-x_uj)\n",
    "        obj = T.sum(T.log(x_uij) - self._lambda_u * (self.M1 ** 2).sum() - \\\n",
    "                    self._lambda_u * (self.M2 ** 2).sum()  - self._lambda_d * (self.K**2) - self._lambda_d * (self.D**2).sum()\\\n",
    "                    - self._lambda_p * (self.N[n2]**2) - self._lambda_p * (self.N[n1]**2)\\\n",
    "                    - self._lambda_A * (self.A1 ** 2).sum() - self._lambda_A * (self.A2 ** 2).sum())\n",
    "        cost = - obj\n",
    "\n",
    "        g_cost_M1 = T.grad(cost=cost, wrt=self.M1)\n",
    "        g_cost_M2 = T.grad(cost=cost, wrt=self.M2)\n",
    "        g_cost_K = T.grad(cost=cost, wrt=self.K)\n",
    "        g_cost_N = T.grad(cost=cost, wrt=self.N)\n",
    "        g_cost_D = T.grad(cost=cost, wrt=self.D)\n",
    "        g_cost_A1 = T.grad(cost=cost, wrt=self.A1)\n",
    "        g_cost_A2 = T.grad(cost=cost, wrt=self.A2)\n",
    "\n",
    "        \n",
    "        updates = [(self.M1, self.M1 - self._learning_rate * .001* g_cost_M1), (self.M2, self.M2 - self._learning_rate *.001* g_cost_M2), \n",
    "                   (self.K, self.K - self._learning_rate * .001*g_cost_K), (self.N, self.N - self._learning_rate *g_cost_N),\n",
    "                  (self.D, self.D - self._learning_rate * g_cost_D), \n",
    "                   (self.A1, self.A1-self._learning_rate * .001 * g_cost_A1), (self.A2, self.A2-self._learning_rate * .001 * g_cost_A2)]\n",
    "\n",
    "        self.train_model_item = theano.function(inputs=[u, i, j, n1, n2, di, dj], outputs=cost, updates=updates)\n",
    "\n",
    "    \n",
    "    def train(self, s_users=None, s_pos_items=None, s_neg_items=None, s_pos_len=None, s_neg_len=None,\n",
    "             s_pos_diversity=None, s_neg_diversity=None,batch_size=1000):\n",
    "        \n",
    "        if len(s_users) < batch_size:\n",
    "            sys.stderr.write(\"WARNING: Batch size is greater than number of training samples, switching to a batch size of %s\\n\" % str(len(train_data)))\n",
    "            batch_size = len(s_users)\n",
    "        \n",
    "        sgd_users, sgd_pos_items, sgd_neg_items = s_users, s_pos_items, s_neg_items\n",
    "        n_sgd_samples = len(s_users)\n",
    "\n",
    "        z = 0\n",
    "        t2 = t1 = t0 = time.time()\n",
    "        while (z+1)*batch_size < n_sgd_samples:\n",
    "            \n",
    "            self.train_model_item(\n",
    "                sgd_users[z*batch_size: (z+1)*batch_size],\n",
    "                sgd_pos_items[z*batch_size: (z+1)*batch_size],\n",
    "                sgd_neg_items[z*batch_size: (z+1)*batch_size],\n",
    "                s_pos_len[z*batch_size: (z+1)*batch_size],\n",
    "                s_neg_len[z*batch_size: (z+1)*batch_size],\n",
    "                s_pos_diversity[z*batch_size: (z+1)*batch_size],\n",
    "                s_neg_diversity[z*batch_size: (z+1)*batch_size],\n",
    "            )\n",
    "            z += 1\n",
    "            t2 = time.time()\n",
    "            sys.stderr.write(\"\\rProcessed %s ( %.2f%% ) in %.4f seconds\" %(str(z*batch_size), 100.0 * float(z*batch_size)/n_sgd_samples, t2 - t1))\n",
    "            sys.stderr.flush()\n",
    "            t1 = t2\n",
    "        if n_sgd_samples > 0:\n",
    "            sys.stderr.write(\"\\nTotal training time %.2f seconds; %e per sample\\n\" % (t2 - t0, (t2 - t0)/n_sgd_samples))\n",
    "            sys.stderr.flush()\n",
    "    \n",
    "    def _generate_test_model_function(self):\n",
    "        u = T.lvector('u')\n",
    "        i = T.lmatrix('i')\n",
    "        j = T.lmatrix('j')\n",
    "        n1 = T.lvector('n1')\n",
    "        n2 = T.lvector('n2')\n",
    "        di = T.dvector('di')\n",
    "        dj = T.dvector('dj')\n",
    "        \n",
    "        x_ui = T.dot(T.dot(self.W1[u],self.M2), T.dot(self.M1, self.H1[i].sum(axis=1).T/n1)).diagonal() + self.K*(self.B1[i].T/n1).T.sum(axis=1) + self.N[n1] + self.D[u]*di + T.dot(T.dot(self.theta1[u],self.A1), T.dot(self.A2, self.TG1[i].sum(axis=1).T/n1)).diagonal()\n",
    "        x_uj = T.dot(T.dot(self.W1[u],self.M2), T.dot(self.M1, self.H1[j].sum(axis=1).T/n2)).diagonal() + self.K*(self.B1[j].T/n2).T.sum(axis=1) + self.N[n2] + self.D[u]*dj + T.dot(T.dot(self.theta1[u],self.A1), T.dot(self.A2, self.TG1[j].sum(axis=1).T/n2)).diagonal()\n",
    "        \n",
    "        x_uij = x_ui-x_uj\n",
    "        self.test_model = theano.function(inputs=[u, i, j, n1, n2, di, dj], outputs=x_uij)\n",
    "        \n",
    "    def test_bundle(self, sgd_users, sgd_pos_items, sgd_neg_items, s_pos_len, s_neg_len, s_pos_diversity, s_neg_diversity, batch_size=1000):\n",
    "        \n",
    "        auc_values = []\n",
    "        z = 0\n",
    "        t2 = t1 = t0 = time.time()\n",
    "        n_sgd_samples = len(sgd_users)\n",
    "        while (z+1)*batch_size < n_sgd_samples:\n",
    "            pref_list=self.test_model(\n",
    "                sgd_users[z*batch_size: (z+1)*batch_size],\n",
    "                sgd_pos_items[z*batch_size: (z+1)*batch_size],\n",
    "                sgd_neg_items[z*batch_size: (z+1)*batch_size],\n",
    "                s_pos_len[z*batch_size: (z+1)*batch_size],\n",
    "                s_neg_len[z*batch_size: (z+1)*batch_size],\n",
    "                s_pos_diversity[z*batch_size: (z+1)*batch_size],\n",
    "                s_neg_diversity[z*batch_size: (z+1)*batch_size]\n",
    "            )\n",
    "            z += 1\n",
    "            t2 = time.time()\n",
    "            sys.stderr.write(\"\\rProcessed %s ( %.2f%% ) in %.4f seconds\" %(str(z*batch_size), 100.0 * float(z*batch_size)/n_sgd_samples, t2 - t1))\n",
    "            t1 = t2\n",
    "            \n",
    "            auc = np.sum([1.0 if a>0.0 else 0.0 for a in pref_list])\n",
    "            auc /= batch_size\n",
    "            \n",
    "            auc_values.append(auc)\n",
    "            sys.stderr.write(\"\\rCurrent AUC mean (%s samples): %0.5f\" % (str(z*batch_size), numpy.mean(auc_values)))\n",
    "            sys.stderr.flush()\n",
    "        \n",
    "        sys.stderr.write(\"\\n\")\n",
    "        sys.stderr.flush()\n",
    "        return numpy.mean(auc_values)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bpr_cold = BPR_Cold(10, max_bundle_size, len(user_bundle_map.keys()), len(items_set), len(tags_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # --- Siyu \n",
    "# # store training and testing data\n",
    "# cPickle.dump(sgd_users, open('../train_test_data2/sgd_users.pkl', 'w'))\n",
    "# cPickle.dump(sgd_pos_items, open('../train_test_data2/sgd_pos_items.pkl', 'w'))\n",
    "# cPickle.dump(sgd_neg_items, open('../train_test_data2/sgd_neg_items.pkl', 'w'))\n",
    "# cPickle.dump(sgd_pos_len, open('../train_test_data2/sgd_pos_len.pkl', 'w'))\n",
    "# cPickle.dump(sgd_neg_len, open('../train_test_data2/sgd_neg_len.pkl', 'w'))\n",
    "# cPickle.dump(sgd_pos_diversity, open('../train_test_data2/sgd_pos_diversity.pkl', 'w'))\n",
    "# cPickle.dump(sgd_neg_diversity, open('../train_test_data2/sgd_neg_diversity.pkl', 'w'))\n",
    "\n",
    "# cPickle.dump(test_users, open('../train_test_data2/test_users.pkl', 'w'))\n",
    "# cPickle.dump(test_pos_items, open('../train_test_data2/test_pos_items.pkl', 'w'))\n",
    "# cPickle.dump(test_neg_items, open('../train_test_data2/test_neg_items.pkl', 'w'))\n",
    "# cPickle.dump(test_n1, open('../train_test_data2/test_n1.pkl', 'w'))\n",
    "# cPickle.dump(test_n2, open('../train_test_data2/test_n2.pkl', 'w'))\n",
    "# cPickle.dump(test_pos_diversity, open('../train_test_data2/test_pos_diversity.pkl', 'w'))\n",
    "# cPickle.dump(test_neg_diversity, open('../train_test_data2/test_neg_diversity.pkl', 'w'))\n",
    "# cPickle.dump(test_pos_bundles, open('../train_test_data2/test_pos_bundles.pkl', 'w'))\n",
    "# cPickle.dump(test_neg_bundles, open('../train_test_data2/test_neg_bundles.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed 4202000 ( 99.99% ) in 0.5871 seconds\n",
      "Total training time 2087.70 seconds; 4.968027e-04 per sample\n"
     ]
    }
   ],
   "source": [
    "bpr_cold.train(s_users=sgd_users, s_pos_items=sgd_pos_items, s_neg_items=sgd_neg_items, \n",
    "          s_pos_len=sgd_pos_len, s_neg_len=sgd_neg_len, s_pos_diversity=sgd_pos_diversity, s_neg_diversity=sgd_neg_diversity)\n",
    "#bpr_cold.train(s_users=sgd_users, s_pos_items=sgd_pos_items, s_neg_items=sgd_neg_items, \n",
    "#          s_pos_len=sgd_pos_len, s_neg_len=sgd_neg_len, s_pos_diversity=sgd_pos_diversity, s_neg_diversity=sgd_neg_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current AUC mean (840000 samples): 0.95902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95902380952380939"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_cold.test_bundle(test_users, test_pos_items, test_neg_items, test_n1, test_n2, test_pos_diversity, test_neg_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bpr_cold.test_bundle(sgd_users, sgd_pos_items, sgd_neg_items, sgd_pos_len, sgd_neg_len, sgd_pos_diversity, sgd_neg_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72220939 -0.0917317   0.55589265 -0.04705987  0.39597294  0.3163124\n",
      " -0.36513358 -0.08407301  0.19462265  0.16555448 -1.49332285  0.47541001\n",
      "  0.96714902  0.99371481  0.23821366  0.03654171  0.63644922  0.12656035\n",
      "  0.53158903  0.79422545  0.44429231 -2.0928793   0.18345444  0.87758791\n",
      "  0.87962162  0.26319507  0.07665071  0.10271587  0.15166678  0.24373242\n",
      "  0.24888457  0.11766978  0.4728429   0.47752514  0.65429634  0.58539778\n",
      "  0.85543835  0.79360145  0.43238908  0.97123146  0.4527472   0.57338786\n",
      "  0.57879388  0.91720694  0.20097978  0.74353015  0.48755497  0.84490806\n",
      "  0.88417828  0.70558339  0.2249916   0.7650243   0.93152517  0.64961135\n",
      "  0.82385176  0.35762936  0.46806589  0.02191768  0.78476524  0.6895445\n",
      "  0.58942312  0.03392347  0.8331511   0.5400126   0.18992491  0.45767501\n",
      "  0.22046806  0.3243283   0.43279713  0.33468181  0.04538137  0.78886545\n",
      "  0.91050959  0.62455404  0.76686895  0.24811046  0.80206877  0.04075332\n",
      "  0.04831307  0.74326617  0.90454739  0.00710959  0.73584795]\n",
      "-0.0295103633007\n"
     ]
    }
   ],
   "source": [
    "print bpr_cold.N.eval()\n",
    "print bpr_cold.D.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_bundle(items_set, user, initial_size = 5, max_iteration = 1000, sample_size = 5):\n",
    "    current_bundle = np.random.choice(list(items_set), initial_size, replace=False)\n",
    "    print \"initial bundle:\", current_bundle\n",
    "    T=1000.0\n",
    "    \n",
    "    ave_bundle_size = []\n",
    "    iteration = 0\n",
    "    while iteration < max_iteration:\n",
    "        iteration+=1\n",
    "        curr_diversity = compute_diversity(current_bundle, Gamma)\n",
    "        user_set=[]\n",
    "        pos_item_set=[]\n",
    "        actual_item_set=[]\n",
    "        neg_item_set=[]\n",
    "        pos_item_count=[]\n",
    "        neg_item_count=[]\n",
    "        pos_diversity=[]\n",
    "        neg_diversity=[]\n",
    "        \n",
    "        \n",
    "        candidate_items = set(np.random.choice(list(items_set), 10, replace=False))\n",
    "        \n",
    "        for item in current_bundle:\n",
    "            if item in candidate_items:\n",
    "                candidate_items.remove(item)\n",
    "        \n",
    "        for ii in range(2):\n",
    "            for jj in range(2, len(candidate_items)):\n",
    "                if len(current_bundle) < 10:\n",
    "                    temp_items = np.random.choice(list(candidate_items), jj, replace=False)\n",
    "                    user_set.append(user)    \n",
    "                    neg_item_set.append(add_bogus_items(current_bundle , max_bundle_size, len(items_set)))\n",
    "                    neg_item_count.append(len(current_bundle))\n",
    "                    neg_diversity.append(curr_diversity)         \n",
    "                    new_bundle=list(current_bundle)\n",
    "                    new_bundle.extend(temp_items)\n",
    "    #                 if len(new_bundle) > 3:\n",
    "    #                     print new_bundle\n",
    "                    pos_item_count.append(len(new_bundle))\n",
    "                    pos_diversity.append(compute_diversity(new_bundle, Gamma))\n",
    "                    actual_item_set.append(new_bundle)\n",
    "                    pos_item_set.append(add_bogus_items(new_bundle , max_bundle_size, len(items_set)))                \n",
    "        \n",
    "        \n",
    "        #Generating new bundles by adding and removing new items  \n",
    "        for cand_item in candidate_items:\n",
    "#             #Add an item case\n",
    "#             if len(current_bundle)<10:\n",
    "#                 user_set.append(user)    \n",
    "#                 neg_item_set.append(add_bogus_items(current_bundle , max_bundle_size, len(items_set)))\n",
    "#                 neg_item_count.append(len(current_bundle))\n",
    "#                 neg_diversity.append(curr_diversity)         \n",
    "#                 new_bundle=list(current_bundle)\n",
    "#                 new_bundle.append(cand_item)\n",
    "# #                 if len(new_bundle) > 3:\n",
    "# #                     print new_bundle\n",
    "#                 pos_item_count.append(len(new_bundle))\n",
    "#                 pos_diversity.append(compute_diversity(new_bundle, Gamma))\n",
    "#                 actual_item_set.append(new_bundle)\n",
    "#                 pos_item_set.append(add_bogus_items(new_bundle , max_bundle_size, len(items_set)))\n",
    "# #                 print 'add pos_item_set:',pos_item_set[-1]\n",
    "                \n",
    "            # Replace an item case\n",
    "            for curr_item in current_bundle:\n",
    "                user_set.append(user)\n",
    "                \n",
    "                neg_item_set.append(add_bogus_items(current_bundle , max_bundle_size, len(items_set)))\n",
    "                neg_item_count.append(len(current_bundle))\n",
    "                neg_diversity.append(curr_diversity)\n",
    "                \n",
    "                new_bundle=list(current_bundle)\n",
    "                new_bundle.append(cand_item)\n",
    "                new_bundle.remove(curr_item)\n",
    "                pos_item_set.append(add_bogus_items(new_bundle , max_bundle_size, len(items_set)))\n",
    "                actual_item_set.append(new_bundle)\n",
    "                pos_item_count.append(len(new_bundle))\n",
    "                pos_diversity.append(compute_diversity(new_bundle, Gamma))\n",
    "         \n",
    "        \n",
    "        # Remove an item case\n",
    "        if len(current_bundle)>2:\n",
    "            for curr_item in current_bundle:\n",
    "                user_set.append(user)\n",
    "\n",
    "                neg_item_set.append(add_bogus_items(current_bundle , max_bundle_size, len(items_set)))\n",
    "                neg_item_count.append(len(current_bundle))\n",
    "                neg_diversity.append(curr_diversity)\n",
    "\n",
    "                new_bundle=list(current_bundle)\n",
    "                new_bundle.remove(curr_item)\n",
    "                actual_item_set.append(new_bundle)\n",
    "                pos_item_set.append(add_bogus_items(new_bundle , max_bundle_size, len(items_set)))\n",
    "                pos_item_count.append(len(new_bundle))\n",
    "                pos_diversity.append(compute_diversity(new_bundle, Gamma))\n",
    "        \n",
    "#         print \"length pos_item_set:\", len(pos_item_set)\n",
    "        pref_score = bpr_cold.test_model(user_set, pos_item_set, neg_item_set, pos_item_count, \n",
    "                                    neg_item_count, pos_diversity, neg_diversity)\n",
    "                                    \n",
    "        #print pref_score, pos_item_count, neg_item_count\n",
    "        index = np.argmax(pref_score)\n",
    "        #print \"Pref Score \", pref_score[index]\n",
    "        if(pref_score[index]>0):\n",
    "            current_bundle = actual_item_set[index]\n",
    "        else:\n",
    "            prob = np.exp(pref_score[index]/T)\n",
    "            if prob < .00001:\n",
    "                break\n",
    "            if np.random.rand() < prob:\n",
    "                current_bundle = actual_item_set[index]\n",
    "        T=T*0.9\n",
    "        ave_bundle_size.append(np.mean(pos_item_count))\n",
    "    print 'average bundle size:', np.mean(ave_bundle_size), \n",
    "    print 'iterations:', len(ave_bundle_size)\n",
    "    #print iteration\n",
    "    print current_bundle\n",
    "    return current_bundle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bogus_items(bundle, max_bundle_size, index):\n",
    "    item=list(bundle);\n",
    "    for i in range(len(item),max_bundle_size):\n",
    "        item.append(index)\n",
    "    return item\n",
    "\n",
    "def remove_bogus_items(bundle, max_bundle_size, index):\n",
    "    item=list(bundle);\n",
    "    i=0\n",
    "    while i< len(bundle):\n",
    "        if bundle[i]==index:\n",
    "            break\n",
    "        i+=1\n",
    "    return bundle[:i]\n",
    "\n",
    "def get_bundle_rank(user, new_bundle, bundle_item_map, bundle_diversity_map):\n",
    "    user_set=[]\n",
    "    pos_item_set=[]\n",
    "    neg_item_set=[]\n",
    "    pos_item_count=[]\n",
    "    neg_item_count=[]\n",
    "    pos_diversity=[]\n",
    "    neg_diversity=[]\n",
    "    \n",
    "    bundle_diversity=compute_diversity(new_bundle, None)\n",
    "    for bundle_id,bundle in bundle_item_map.items():\n",
    "        user_set.append(user)\n",
    "        pos_item_set.append(add_bogus_items(bundle, max_bundle_size, len(items_set)))\n",
    "        neg_item_set.append(add_bogus_items(new_bundle, max_bundle_size, len(items_set)))\n",
    "        pos_item_count.append(len(bundle))\n",
    "        neg_item_count.append(len(new_bundle))\n",
    "        pos_diversity.append(bundle_diversity_map[bundle_id])\n",
    "        neg_diversity.append(bundle_diversity)\n",
    "        \n",
    "    pref_score = bpr_cold.test_model(user_set, pos_item_set, neg_item_set, pos_item_count, \n",
    "                                    neg_item_count, pos_diversity, neg_diversity)\n",
    "  \n",
    "    rank = np.sum([1.0 if p>0 else 0.0 for p in pref_score])\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial bundle: [2041 1997 2355   29]\n",
      "average bundle size: 11.8542754275 iterations: 101\n",
      "[164, 1957, 848, 2135, 106, 2103, 1909, 4, 1744, 397, 999, 117]\n",
      "Rank of user 0 : 3, Size of bundle : 12, Bundles purchased : 6 Aggregate diversity: 12 Score: 4.000000, Average bundle size: 12.000000\n",
      "initial bundle: [ 720   64  407 1228]\n",
      "average bundle size: 4.50482131094 iterations: 92\n",
      "[24, 1784]\n",
      "Rank of user 1 : 1, Size of bundle : 2, Bundles purchased : 15 Aggregate diversity: 14 Score: 3.000000, Average bundle size: 7.000000\n",
      "initial bundle: [2499 2453 1281 1109]\n",
      "average bundle size: 4.48390589569 iterations: 80\n",
      "[733, 341]\n",
      "Rank of user 2 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 16 Score: 2.333333, Average bundle size: 5.333333\n",
      "initial bundle: [1382 1277  302 1336]\n",
      "average bundle size: 4.50550501325 iterations: 83\n",
      "[124, 132]\n",
      "Rank of user 3 : 2, Size of bundle : 2, Bundles purchased : 7 Aggregate diversity: 18 Score: 2.500000, Average bundle size: 4.500000\n",
      "initial bundle: [1195 2015 1487 1840]\n",
      "average bundle size: 4.50624965433 iterations: 82\n",
      "[66, 2347]\n",
      "Rank of user 4 : 0, Size of bundle : 2, Bundles purchased : 8 Aggregate diversity: 20 Score: 2.200000, Average bundle size: 4.000000\n",
      "initial bundle: [2234  419 1148 1164]\n",
      "average bundle size: 4.55420061029 iterations: 81\n",
      "[733, 223]\n",
      "Rank of user 5 : 0, Size of bundle : 2, Bundles purchased : 5 Aggregate diversity: 21 Score: 2.000000, Average bundle size: 3.666667\n",
      "initial bundle: [2369 1842 1030 2474]\n",
      "average bundle size: 4.51026297965 iterations: 77\n",
      "[397, 132]\n",
      "Rank of user 6 : 1, Size of bundle : 2, Bundles purchased : 4 Aggregate diversity: 21 Score: 2.000000, Average bundle size: 3.428571\n",
      "initial bundle: [1946 1052  275  816]\n",
      "average bundle size: 4.52166986453 iterations: 78\n",
      "[2064, 1746]\n",
      "Rank of user 7 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 23 Score: 1.875000, Average bundle size: 3.250000\n",
      "initial bundle: [1779 1724 1854 2105]\n",
      "average bundle size: 11.3179981635 iterations: 99\n",
      "[1324, 2132, 237, 2336, 848, 138, 1817, 547, 345, 268, 24]\n",
      "Rank of user 8 : 0, Size of bundle : 11, Bundles purchased : 7 Aggregate diversity: 32 Score: 1.777778, Average bundle size: 4.111111\n",
      "initial bundle: [2123 1444 2340 2254]\n",
      "average bundle size: 4.52847186791 iterations: 80\n",
      "[1886, 788]\n",
      "Rank of user 9 : 1, Size of bundle : 2, Bundles purchased : 8 Aggregate diversity: 34 Score: 1.800000, Average bundle size: 3.900000\n",
      "initial bundle: [ 308 1276 1837  908]\n",
      "average bundle size: 4.58664457236 iterations: 78\n",
      "[132, 1886]\n",
      "Rank of user 10 : 0, Size of bundle : 2, Bundles purchased : 5 Aggregate diversity: 34 Score: 1.727273, Average bundle size: 3.727273\n",
      "initial bundle: [2228 1475  184 1431]\n",
      "average bundle size: 4.50851820358 iterations: 90\n",
      "[74, 85]\n",
      "Rank of user 11 : 1, Size of bundle : 2, Bundles purchased : 2 Aggregate diversity: 36 Score: 1.750000, Average bundle size: 3.583333\n",
      "initial bundle: [ 697  956  835 1671]\n",
      "average bundle size: 4.48653665911 iterations: 75\n",
      "[142, 4]\n",
      "Rank of user 12 : 0, Size of bundle : 2, Bundles purchased : 10 Aggregate diversity: 37 Score: 1.692308, Average bundle size: 3.461538\n",
      "initial bundle: [1701 2128  619 2280]\n",
      "average bundle size: 11.9133274492 iterations: 103\n",
      "[1154, 1875, 129, 345, 1310, 1047, 397, 213, 1990, 726, 2225, 148]\n",
      "Rank of user 13 : 2, Size of bundle : 12, Bundles purchased : 1 Aggregate diversity: 47 Score: 1.785714, Average bundle size: 4.071429\n",
      "initial bundle: [2103  516  613 2422]\n",
      "average bundle size: 4.50779478458 iterations: 80\n",
      "[1154, 1728]\n",
      "Rank of user 14 : 3, Size of bundle : 2, Bundles purchased : 8 Aggregate diversity: 48 Score: 1.933333, Average bundle size: 3.933333\n",
      "initial bundle: [  65 2207 1137 1784]\n",
      "average bundle size: 4.5675170068 iterations: 80\n",
      "[4, 237]\n",
      "Rank of user 15 : 1, Size of bundle : 2, Bundles purchased : 8 Aggregate diversity: 48 Score: 1.937500, Average bundle size: 3.812500\n",
      "initial bundle: [2255  740  958 2406]\n",
      "average bundle size: 4.46844958148 iterations: 81\n",
      "[733, 268]\n",
      "Rank of user 16 : 3, Size of bundle : 2, Bundles purchased : 4 Aggregate diversity: 48 Score: 2.058824, Average bundle size: 3.705882\n",
      "initial bundle: [1656 2344  694   53]\n",
      "average bundle size: 4.46580484514 iterations: 79\n",
      "[813, 735]\n",
      "Rank of user 17 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 50 Score: 2.000000, Average bundle size: 3.611111\n",
      "initial bundle: [1628 1033 1454  693]\n",
      "average bundle size: 4.53678868373 iterations: 84\n",
      "[425, 1281]\n",
      "Rank of user 18 : 7, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 52 Score: 2.315789, Average bundle size: 3.526316\n",
      "initial bundle: [ 168 2034   69  940]\n",
      "average bundle size: 4.50240929705 iterations: 83\n",
      "[2345, 1707]\n",
      "Rank of user 19 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 54 Score: 2.250000, Average bundle size: 3.450000\n",
      "initial bundle: [1599 1194 2296  310]\n",
      "average bundle size: 4.50458297902 iterations: 80\n",
      "[1399, 735]\n",
      "Rank of user 20 : 3, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 55 Score: 2.333333, Average bundle size: 3.380952\n",
      "initial bundle: [2237  455  839 2048]\n",
      "average bundle size: 4.47482993197 iterations: 82\n",
      "[2132, 1948]\n",
      "Rank of user 21 : 1, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 56 Score: 2.318182, Average bundle size: 3.318182\n",
      "initial bundle: [2191 1104  396  409]\n",
      "average bundle size: 4.48390589569 iterations: 80\n",
      "[733, 120]\n",
      "Rank of user 22 : 0, Size of bundle : 2, Bundles purchased : 4 Aggregate diversity: 57 Score: 2.260870, Average bundle size: 3.260870\n",
      "initial bundle: [1381 1472  634 2142]\n",
      "average bundle size: 4.57816504509 iterations: 86\n",
      "[4, 2481]\n",
      "Rank of user 23 : 0, Size of bundle : 2, Bundles purchased : 2 Aggregate diversity: 58 Score: 2.208333, Average bundle size: 3.208333\n",
      "initial bundle: [1008  921  111  586]\n",
      "average bundle size: 4.5616564086 iterations: 84\n",
      "[733, 528]\n",
      "Rank of user 24 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 59 Score: 2.160000, Average bundle size: 3.160000\n",
      "initial bundle: [2180 1070 1327  867]\n",
      "average bundle size: 4.59575986096 iterations: 76\n",
      "[24, 813]\n",
      "Rank of user 25 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 59 Score: 2.115385, Average bundle size: 3.115385\n",
      "initial bundle: [1091 1438 1204  122]\n",
      "average bundle size: 4.4898035881 iterations: 85\n",
      "[733, 1217]\n",
      "Rank of user 26 : 1, Size of bundle : 2, Bundles purchased : 2 Aggregate diversity: 60 Score: 2.111111, Average bundle size: 3.074074\n",
      "initial bundle: [1764 2430  978  496]\n",
      "average bundle size: 4.53060664595 iterations: 81\n",
      "[721, 2225]\n",
      "Rank of user 27 : 1, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 61 Score: 2.107143, Average bundle size: 3.035714\n",
      "initial bundle: [1537 1251  772 2313]\n",
      "average bundle size: 4.56682453572 iterations: 79\n",
      "[239, 8]\n",
      "Rank of user 28 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 63 Score: 2.068966, Average bundle size: 3.000000\n",
      "initial bundle: [2384 1505 1985  497]\n",
      "average bundle size: 4.53392057678 iterations: 78\n",
      "[1324, 268]\n",
      "Rank of user 29 : 4, Size of bundle : 2, Bundles purchased : 4 Aggregate diversity: 63 Score: 2.166667, Average bundle size: 2.966667\n",
      "initial bundle: [1577  501 1123  966]\n",
      "average bundle size: 11.8464069264 iterations: 105\n",
      "[1035, 4, 2295, 246, 10, 88, 953, 120, 1601, 733, 774, 2260]\n",
      "Rank of user 30 : 3, Size of bundle : 12, Bundles purchased : 1 Aggregate diversity: 72 Score: 2.225806, Average bundle size: 3.258065\n",
      "initial bundle: [1297  685 1602 1475]\n",
      "average bundle size: 4.50557256236 iterations: 80\n",
      "[425, 1601]\n",
      "Rank of user 31 : 3, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 72 Score: 2.281250, Average bundle size: 3.218750\n",
      "initial bundle: [ 573  764  878 1025]\n",
      "average bundle size: 10.9863425926 iterations: 96\n",
      "[1648, 2308, 136, 386, 2120, 1035, 1324, 788, 733, 1797, 268]\n",
      "Rank of user 32 : 0, Size of bundle : 11, Bundles purchased : 3 Aggregate diversity: 78 Score: 2.242424, Average bundle size: 3.454545\n",
      "initial bundle: [ 642 1628 2141 1285]\n",
      "average bundle size: 11.9319456245 iterations: 107\n",
      "[2414, 2123, 757, 999, 467, 74, 2499, 1835, 551, 227, 148, 1828]\n",
      "Rank of user 33 : 0, Size of bundle : 12, Bundles purchased : 8 Aggregate diversity: 87 Score: 2.205882, Average bundle size: 3.705882\n",
      "initial bundle: [ 173  335 1259 1039]\n",
      "average bundle size: 11.0402870813 iterations: 95\n",
      "[458, 481, 2094, 206, 733, 1003, 1392, 1957, 1990, 223, 1281]\n",
      "Rank of user 34 : 4, Size of bundle : 11, Bundles purchased : 5 Aggregate diversity: 93 Score: 2.285714, Average bundle size: 3.914286\n",
      "initial bundle: [ 587  978 1044  470]\n",
      "average bundle size: 4.50859668762 iterations: 79\n",
      "[382, 1886]\n",
      "Rank of user 35 : 2, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 94 Score: 2.305556, Average bundle size: 3.861111\n",
      "initial bundle: [ 66 385 963 817]\n",
      "average bundle size: 4.47162173511 iterations: 81\n",
      "[66, 901]\n",
      "Rank of user 36 : 1, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 95 Score: 2.297297, Average bundle size: 3.810811\n",
      "initial bundle: [ 407 1341   94 1248]\n",
      "average bundle size: 4.52642241856 iterations: 82\n",
      "[1679, 735]\n",
      "Rank of user 37 : 1, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 96 Score: 2.289474, Average bundle size: 3.763158\n",
      "initial bundle: [1779  444 1653 1783]\n",
      "average bundle size: 11.4875587559 iterations: 101\n",
      "[541, 1964, 72, 1581, 1746, 117, 1566, 1875, 582, 22, 632]\n",
      "Rank of user 38 : 10, Size of bundle : 11, Bundles purchased : 11 Aggregate diversity: 104 Score: 2.512821, Average bundle size: 3.948718\n",
      "initial bundle: [ 670  325  490 2219]\n",
      "average bundle size: 4.51112901301 iterations: 76\n",
      "[1601, 1399]\n",
      "Rank of user 39 : 0, Size of bundle : 2, Bundles purchased : 5 Aggregate diversity: 104 Score: 2.475000, Average bundle size: 3.900000\n",
      "initial bundle: [1478 1839  263    6]\n",
      "average bundle size: 4.48632252901 iterations: 85\n",
      "[66, 1129]\n",
      "Rank of user 40 : 1, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 105 Score: 2.463415, Average bundle size: 3.853659\n",
      "initial bundle: [1345 1537 1974 2139]\n",
      "average bundle size: 4.5166148764 iterations: 81\n",
      "[733, 582]\n",
      "Rank of user 41 : 1, Size of bundle : 2, Bundles purchased : 2 Aggregate diversity: 105 Score: 2.452381, Average bundle size: 3.809524\n",
      "initial bundle: [2018  280   77 1562]\n",
      "average bundle size: 12.0085714286 iterations: 105\n",
      "[436, 290, 1771, 74, 1199, 423, 1758, 1658, 1649, 851, 2327, 164]\n",
      "Rank of user 42 : 3, Size of bundle : 12, Bundles purchased : 1 Aggregate diversity: 115 Score: 2.488372, Average bundle size: 4.000000\n",
      "initial bundle: [2234  471  224 1497]\n",
      "average bundle size: 4.52166986453 iterations: 78\n",
      "[4, 24]\n",
      "Rank of user 43 : 0, Size of bundle : 2, Bundles purchased : 5 Aggregate diversity: 115 Score: 2.454545, Average bundle size: 3.954545\n",
      "initial bundle: [1536 1045 2353  501]\n",
      "average bundle size: 4.49399229571 iterations: 83\n",
      "[397, 138]\n",
      "Rank of user 44 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 115 Score: 2.422222, Average bundle size: 3.911111\n",
      "initial bundle: [ 451 2225 1123 2053]\n",
      "average bundle size: 4.49034357791 iterations: 84\n",
      "[733, 148]\n",
      "Rank of user 45 : 0, Size of bundle : 2, Bundles purchased : 5 Aggregate diversity: 115 Score: 2.391304, Average bundle size: 3.869565\n",
      "initial bundle: [1105 1036  193  679]\n",
      "average bundle size: 11.1280148423 iterations: 98\n",
      "[471, 2260, 838, 1886, 2229, 962, 223, 2170, 1950, 1504, 371]\n",
      "Rank of user 46 : 0, Size of bundle : 11, Bundles purchased : 3 Aggregate diversity: 123 Score: 2.361702, Average bundle size: 4.021277\n",
      "initial bundle: [ 253  292 1062 1075]\n",
      "average bundle size: 10.9140762463 iterations: 93\n",
      "[813, 1122, 1047, 2132, 1341, 399, 2347, 1460, 2159, 393, 60]\n",
      "Rank of user 47 : 1, Size of bundle : 11, Bundles purchased : 1 Aggregate diversity: 130 Score: 2.354167, Average bundle size: 4.166667\n",
      "initial bundle: [171 596 337 551]\n",
      "average bundle size: 4.48260196623 iterations: 76\n",
      "[88, 1399]\n",
      "Rank of user 48 : 0, Size of bundle : 2, Bundles purchased : 4 Aggregate diversity: 130 Score: 2.326531, Average bundle size: 4.122449\n",
      "initial bundle: [ 199 2506 2176  271]\n",
      "average bundle size: 4.50001546073 iterations: 88\n",
      "[1601, 603]\n",
      "Rank of user 49 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 131 Score: 2.300000, Average bundle size: 4.080000\n",
      "initial bundle: [ 373 1392  963  948]\n",
      "average bundle size: 4.48313455252 iterations: 77\n",
      "[425, 731]\n",
      "Rank of user 50 : 3, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 132 Score: 2.333333, Average bundle size: 4.039216\n",
      "initial bundle: [1744  113  555 1865]\n",
      "average bundle size: 4.51201814059 iterations: 75\n",
      "[71, 1835]\n",
      "Rank of user 51 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 133 Score: 2.307692, Average bundle size: 4.000000\n",
      "initial bundle: [1948   85 2399  135]\n",
      "average bundle size: 4.47790048509 iterations: 79\n",
      "[1281, 132]\n",
      "Rank of user 52 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 133 Score: 2.283019, Average bundle size: 3.962264\n",
      "initial bundle: [425 507 484 856]\n",
      "average bundle size: 4.55372678607 iterations: 79\n",
      "[2345, 1460]\n",
      "Rank of user 53 : 2, Size of bundle : 2, Bundles purchased : 2 Aggregate diversity: 133 Score: 2.296296, Average bundle size: 3.925926\n",
      "initial bundle: [1342  873 1214 1822]\n",
      "average bundle size: 4.49585034014 iterations: 80\n",
      "[1324, 2146]\n",
      "Rank of user 54 : 1, Size of bundle : 2, Bundles purchased : 2 Aggregate diversity: 134 Score: 2.290909, Average bundle size: 3.890909\n",
      "initial bundle: [2476 1624 1981 1359]\n",
      "average bundle size: 4.51026297965 iterations: 77\n",
      "[372, 138]\n",
      "Rank of user 55 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 135 Score: 2.267857, Average bundle size: 3.857143\n",
      "initial bundle: [1345  439  483  958]\n",
      "average bundle size: 4.49855591359 iterations: 76\n",
      "[733, 2157]\n",
      "Rank of user 56 : 0, Size of bundle : 2, Bundles purchased : 2 Aggregate diversity: 136 Score: 2.245614, Average bundle size: 3.824561\n",
      "initial bundle: [ 287 1887 2066 1456]\n",
      "average bundle size: 4.52752118391 iterations: 76\n",
      "[1035, 1992]\n",
      "Rank of user 57 : 3, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 137 Score: 2.275862, Average bundle size: 3.793103\n",
      "initial bundle: [ 268 2469  150  192]\n",
      "average bundle size: 4.47419255991 iterations: 74\n",
      "[213, 2123]\n",
      "Rank of user 58 : 0, Size of bundle : 2, Bundles purchased : 4 Aggregate diversity: 137 Score: 2.254237, Average bundle size: 3.762712\n",
      "initial bundle: [ 117 2439 2409  999]\n",
      "average bundle size: 11.8471698113 iterations: 106\n",
      "[2489, 1957, 2195, 26, 165, 2117, 1392, 399, 1115, 219, 328, 458]\n",
      "Rank of user 59 : 3, Size of bundle : 12, Bundles purchased : 5 Aggregate diversity: 145 Score: 2.283333, Average bundle size: 3.900000\n",
      "initial bundle: [2072 1798 1826  958]\n",
      "average bundle size: 4.48899962207 iterations: 75\n",
      "[448, 2159]\n",
      "Rank of user 60 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 146 Score: 2.262295, Average bundle size: 3.868852\n",
      "initial bundle: [ 685  793 1939 2503]\n",
      "average bundle size: 4.51112901301 iterations: 76\n",
      "[167, 1886]\n",
      "Rank of user 61 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 147 Score: 2.241935, Average bundle size: 3.838710\n",
      "initial bundle: [ 441  825 1169 1055]\n",
      "average bundle size: 4.48294342127 iterations: 82\n",
      "[7, 2347]\n",
      "Rank of user 62 : 1, Size of bundle : 2, Bundles purchased : 5 Aggregate diversity: 148 Score: 2.238095, Average bundle size: 3.809524\n",
      "initial bundle: [1809  729  329 2365]\n",
      "average bundle size: 11.3482093664 iterations: 99\n",
      "[1154, 733, 1853, 819, 2285, 397, 2345, 2120, 425, 757, 165]\n",
      "Rank of user 63 : 3, Size of bundle : 11, Bundles purchased : 5 Aggregate diversity: 151 Score: 2.265625, Average bundle size: 3.921875\n",
      "initial bundle: [1737 1909 1759 1880]\n",
      "average bundle size: 4.51309490066 iterations: 84\n",
      "[1504, 2159]\n",
      "Rank of user 64 : 1, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 151 Score: 2.261538, Average bundle size: 3.892308\n",
      "initial bundle: [  81 1206 2392 2226]\n",
      "average bundle size: 4.51880966378 iterations: 81\n",
      "[768, 379]\n",
      "Rank of user 65 : 2, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 153 Score: 2.272727, Average bundle size: 3.863636\n",
      "initial bundle: [1195 1257 1020  158]\n",
      "average bundle size: 4.48491772777 iterations: 78\n",
      "[733, 268]\n",
      "Rank of user 66 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 153 Score: 2.253731, Average bundle size: 3.835821\n",
      "initial bundle: [  41  973  332 1002]\n",
      "average bundle size: 4.54004316586 iterations: 83\n",
      "[481, 1324]\n",
      "Rank of user 67 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 153 Score: 2.235294, Average bundle size: 3.808824\n",
      "initial bundle: [1128  573  643 1035]\n",
      "average bundle size: 4.48253894631 iterations: 77\n",
      "[726, 1129]\n",
      "Rank of user 68 : 1, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 153 Score: 2.231884, Average bundle size: 3.782609\n",
      "initial bundle: [1082  400 2513 1847]\n",
      "average bundle size: 4.48260196623 iterations: 76\n",
      "[1324, 393]\n",
      "Rank of user 69 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 153 Score: 2.214286, Average bundle size: 3.757143\n",
      "initial bundle: [2383  357  248 1724]\n",
      "average bundle size: 4.47266701552 iterations: 78\n",
      "[2347, 1756]\n",
      "Rank of user 70 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 154 Score: 2.197183, Average bundle size: 3.732394\n",
      "initial bundle: [2385  490 1349  375]\n",
      "average bundle size: 4.48544335483 iterations: 77\n",
      "[733, 345]\n",
      "Rank of user 71 : 0, Size of bundle : 2, Bundles purchased : 4 Aggregate diversity: 154 Score: 2.180556, Average bundle size: 3.708333\n",
      "initial bundle: [1468  450 1886 2114]\n",
      "average bundle size: 4.46994949495 iterations: 78\n",
      "[1886, 733]\n",
      "Rank of user 72 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 154 Score: 2.164384, Average bundle size: 3.684932\n",
      "initial bundle: [2293  939 2066 1874]\n",
      "average bundle size: 4.49650104768 iterations: 79\n",
      "[733, 954]\n",
      "Rank of user 73 : 0, Size of bundle : 2, Bundles purchased : 2 Aggregate diversity: 155 Score: 2.148649, Average bundle size: 3.662162\n",
      "initial bundle: [ 184  597 1386  841]\n",
      "average bundle size: 4.4945965378 iterations: 82\n",
      "[1047, 1581]\n",
      "Rank of user 74 : 2, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 155 Score: 2.160000, Average bundle size: 3.640000\n",
      "initial bundle: [2007  496 1712  822]\n",
      "average bundle size: 11.0972170686 iterations: 98\n",
      "[1281, 1886, 1845, 223, 481, 1204, 233, 457, 1820, 1746, 371]\n",
      "Rank of user 75 : 0, Size of bundle : 11, Bundles purchased : 3 Aggregate diversity: 160 Score: 2.144737, Average bundle size: 3.736842\n",
      "initial bundle: [1332 1751 1938 1317]\n",
      "average bundle size: 4.49399229571 iterations: 83\n",
      "[393, 380]\n",
      "Rank of user 76 : 2, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 161 Score: 2.155844, Average bundle size: 3.714286\n",
      "initial bundle: [2375 1847 1626 1502]\n",
      "average bundle size: 4.50941915228 iterations: 78\n",
      "[1399, 1875]\n",
      "Rank of user 77 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 161 Score: 2.141026, Average bundle size: 3.692308\n",
      "initial bundle: [2433 2172 1895 1144]\n",
      "average bundle size: 4.57654462534 iterations: 89\n",
      "[1554, 397]\n",
      "Rank of user 78 : 2, Size of bundle : 2, Bundles purchased : 2 Aggregate diversity: 162 Score: 2.151899, Average bundle size: 3.670886\n",
      "initial bundle: [2401  135  133  638]\n",
      "average bundle size: 4.47379591837 iterations: 75\n",
      "[721, 436]\n",
      "Rank of user 79 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 162 Score: 2.137500, Average bundle size: 3.650000\n",
      "initial bundle: [1765  898  322  991]\n",
      "average bundle size: 4.49117707689 iterations: 88\n",
      "[1129, 437]\n",
      "Rank of user 80 : 1, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 163 Score: 2.135802, Average bundle size: 3.629630\n",
      "initial bundle: [1060 1311 1472 1694]\n",
      "average bundle size: 4.50779478458 iterations: 80\n",
      "[1581, 87]\n",
      "Rank of user 81 : 3, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 164 Score: 2.158537, Average bundle size: 3.609756\n",
      "initial bundle: [1550 2085  604  945]\n",
      "average bundle size: 11.9131118881 iterations: 104\n",
      "[735, 209, 1319, 1909, 206, 1728, 1790, 1784, 532, 733, 423, 142]\n",
      "Rank of user 82 : 1, Size of bundle : 12, Bundles purchased : 4 Aggregate diversity: 168 Score: 2.156627, Average bundle size: 3.710843\n",
      "initial bundle: [  54  819 1571  263]\n",
      "average bundle size: 4.49725988569 iterations: 73\n",
      "[1886, 1728]\n",
      "Rank of user 83 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 168 Score: 2.142857, Average bundle size: 3.690476\n",
      "initial bundle: [2118 2074 1426 1807]\n",
      "average bundle size: 4.47096686064 iterations: 83\n",
      "[5, 2149]\n",
      "Rank of user 84 : 4, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 170 Score: 2.176471, Average bundle size: 3.670588\n",
      "initial bundle: [1592 1541  585  920]\n",
      "average bundle size: 4.5295558874 iterations: 82\n",
      "[1845, 1973]\n",
      "Rank of user 85 : 1, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 171 Score: 2.174419, Average bundle size: 3.651163\n",
      "initial bundle: [ 882  201  432 1657]\n",
      "average bundle size: 4.53392057678 iterations: 78\n",
      "[7, 1399]\n",
      "Rank of user 86 : 0, Size of bundle : 2, Bundles purchased : 6 Aggregate diversity: 171 Score: 2.160920, Average bundle size: 3.632184\n",
      "initial bundle: [1923   19 1007  463]\n",
      "average bundle size: 4.55047432475 iterations: 79\n",
      "[733, 2146]\n",
      "Rank of user 87 : 0, Size of bundle : 2, Bundles purchased : 5 Aggregate diversity: 171 Score: 2.147727, Average bundle size: 3.613636\n",
      "initial bundle: [ 667  340 2053 1678]\n",
      "average bundle size: 4.5053442263 iterations: 79\n",
      "[7, 88]\n",
      "Rank of user 88 : 1, Size of bundle : 2, Bundles purchased : 12 Aggregate diversity: 171 Score: 2.146067, Average bundle size: 3.595506\n",
      "initial bundle: [2264 1284 1465 1209]\n",
      "average bundle size: 4.52370211242 iterations: 76\n",
      "[1601, 88]\n",
      "Rank of user 89 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 171 Score: 2.133333, Average bundle size: 3.577778\n",
      "initial bundle: [1153 1953  323  633]\n",
      "average bundle size: 4.51973922902 iterations: 80\n",
      "[2157, 111]\n",
      "Rank of user 90 : 2, Size of bundle : 2, Bundles purchased : 5 Aggregate diversity: 172 Score: 2.142857, Average bundle size: 3.560440\n",
      "initial bundle: [2448  763 1714 1882]\n",
      "average bundle size: 4.53278796751 iterations: 79\n",
      "[2444, 1129]\n",
      "Rank of user 91 : 1, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 173 Score: 2.141304, Average bundle size: 3.543478\n",
      "initial bundle: [1563  339  418  825]\n",
      "average bundle size: 4.50941915228 iterations: 78\n",
      "[107, 436]\n",
      "Rank of user 92 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 174 Score: 2.129032, Average bundle size: 3.526882\n",
      "initial bundle: [1034 1764 2326 1041]\n",
      "average bundle size: 4.54137692114 iterations: 72\n",
      "[1728, 656]\n",
      "Rank of user 93 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 175 Score: 2.117021, Average bundle size: 3.510638\n",
      "initial bundle: [  32 1651  138 2323]\n",
      "average bundle size: 4.48247957818 iterations: 83\n",
      "[1875, 126]\n",
      "Rank of user 94 : 2, Size of bundle : 2, Bundles purchased : 2 Aggregate diversity: 176 Score: 2.126316, Average bundle size: 3.494737\n",
      "initial bundle: [533 366 371 133]\n",
      "average bundle size: 4.48069409014 iterations: 80\n",
      "[457, 721]\n",
      "Rank of user 95 : 0, Size of bundle : 2, Bundles purchased : 6 Aggregate diversity: 176 Score: 2.114583, Average bundle size: 3.479167\n",
      "initial bundle: [1082 1582 1178  499]\n",
      "average bundle size: 4.47181714458 iterations: 79\n",
      "[2259, 136]\n",
      "Rank of user 96 : 0, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 177 Score: 2.103093, Average bundle size: 3.463918\n",
      "initial bundle: [1107 2487 2156 2173]\n",
      "average bundle size: 4.51228724823 iterations: 85\n",
      "[397, 1663]\n",
      "Rank of user 97 : 5, Size of bundle : 2, Bundles purchased : 3 Aggregate diversity: 178 Score: 2.142857, Average bundle size: 3.448980\n",
      "initial bundle: [1794  600 1877 1079]\n",
      "average bundle size: 11.2133636364 iterations: 100\n",
      "[7, 1691, 1415, 448, 1122, 1421, 813, 397, 138, 754, 1725]\n",
      "Rank of user 98 : 4, Size of bundle : 11, Bundles purchased : 5 Aggregate diversity: 183 Score: 2.171717, Average bundle size: 3.525253\n",
      "initial bundle: [ 120 2346 2417 2223]\n",
      "average bundle size: 4.48069409014 iterations: 80\n",
      "[733, 1875]\n",
      "Rank of user 99 : 0, Size of bundle : 2, Bundles purchased : 1 Aggregate diversity: 183 Score: 2.160000, Average bundle size: 3.510000\n"
     ]
    }
   ],
   "source": [
    "sizes=[10]\n",
    "diversities=[]\n",
    "scores=[]\n",
    "bundle_sizes=[]\n",
    "for size in sizes:\n",
    "    aggregate_diversity=set()\n",
    "    pred_score=[]\n",
    "    b_size=[]\n",
    "    generated_bundles=[]\n",
    "    for user in sorted(user_bundle_map.keys())[:100]:\n",
    "        new_bundle = generate_bundle(items_set, user, 4, 1000,size)\n",
    "        rank = get_bundle_rank(user, new_bundle, bundle_item_map, bundle_diversity_map)\n",
    "        purchased_bundles = len(user_bundle_map[user])\n",
    "        aggregate_diversity=aggregate_diversity.union(set(new_bundle))\n",
    "        generated_bundles.append(new_bundle)\n",
    "        pred_score.append(rank)\n",
    "        b_size.append(len(new_bundle)*1.0)\n",
    "        print 'Rank of user %d : %d, Size of bundle : %d, Bundles purchased : %d Aggregate diversity: %d Score: %f, Average bundle size: %f' %(user, \n",
    "                                                                                     rank, \n",
    "                                                                                     len(new_bundle),                                 \n",
    "                                                                                     purchased_bundles,\n",
    "                                                                                     len(aggregate_diversity),\n",
    "                                                                                     1.0+np.mean(pred_score),\n",
    "                                                                                     np.mean(b_size))\n",
    "    diversities.append(len(aggregate_diversity))\n",
    "    scores.append(1.0+np.mean(pred_score))\n",
    "    bundle_sizes.append(np.mean(b_size)*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    }
   ],
   "source": [
    "print 'abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print scores\n",
    "print diversities\n",
    "print bundle_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
